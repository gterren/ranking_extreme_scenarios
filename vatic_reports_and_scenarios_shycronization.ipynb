{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af28414c-ca10-4d60-b167-15d4b97d2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, bz2, pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "\n",
    "from time import time\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, jaccard_score, f1_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# # #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "# rc('font',**{'family':'serif','serif':['Computer Modern']})\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'silver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47bca35-a4e3-4d91-ab8a-2caa41d8f619",
   "metadata": {},
   "source": [
    "# Shyncronize Vatic reports with clnSim scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd26abc-80cb-45f6-8e37-832d4900c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to data (stract inside Sim* files)\n",
    "path_to_vatic  = r\"/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/\"\n",
    "path_to_data   = r\"/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/\"\n",
    "path_to_fdepth = r\"/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/FunctionalDepthsTexas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61ffdb-371a-46a3-9b1d-9971f1a82cdb",
   "metadata": {},
   "source": [
    "## Step 1: processing Vatic reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f27af20f-e5a2-4361-b80a-1d89b2356dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-07-22\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-10-04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-08-08\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-07-24\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-03-14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-02-13\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-02-14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-01-02\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-11-02\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-12-01\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-05-27\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-09-14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-05-10\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-01-20\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-06-30\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-10-17\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-04-01\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-04-09\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-09-04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-02-26\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-12-27\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-06-04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-11-13\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-04-24\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/VaticReportTexas/2018-08-18\n"
     ]
    }
   ],
   "source": [
    "# Load vatic summary for each scenario in given date\n",
    "def _load_vatic_summary(path):\n",
    "    idx_ = []\n",
    "    summaries_ = []\n",
    "    for file_ in glob.glob(path + r'/*'):\n",
    "        \n",
    "        idx_.append(int(file_[50 + file_[50:].find('_s') + 2:-11]))\n",
    "        summaries_.append(pd.read_pickle(file_).to_numpy()[..., np.newaxis])\n",
    "\n",
    "    return np.concatenate(summaries_, axis = 2)[..., np.argsort(np.array(idx_))]\n",
    "\n",
    "\n",
    "# Load clnSim compressed scenarios file\n",
    "def _load_clnSim_scen(date, path):\n",
    "    with bz2.BZ2File(path + 'scens_{}.p.gz'.format(date), 'r') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "# Format scenarios file per cohort\n",
    "def _get_assets_in_cohort(scen_, cohorts_):\n",
    "    return [np.concatenate([scen_[cohort].to_numpy()[:, i*24:(i + 1)*24][..., np.newaxis] \n",
    "                     for i in range(int(scen_[cohort].shape[1]/24))], axis = 2) for cohort in cohorts_]\n",
    "        \n",
    "# Find All Simulations per Dates/Folders\n",
    "files_ = glob.glob(path_to_vatic + r'VaticReportTexas/*')\n",
    "for file_ in files_:\n",
    "    print(file_)\n",
    "    \n",
    "    # Crate directory if it does not exist\n",
    "    if os.path.exists(path_to_vatic + pd.to_datetime(file_[-10:]).strftime(\"%b%d\")):\n",
    "\n",
    "        Summary_ = _load_vatic_summary(file_)[:, [1, 2, 8, 5], :]\n",
    "        print(Summary_.shape)\n",
    "        df_ = pd.DataFrame(np.sum(Summary_[:, ...], axis = 0).T, columns = ['GenerationCostAll', \n",
    "                                                                             'LoadSheddingAll', \n",
    "                                                                             'RenewableCurtailmentAll', \n",
    "                                                                             'ReserveShortfallAll'])\n",
    "        df_.to_csv(path_to_vatic + r'ProcessedDataTexas/' + pd.to_datetime(file_[-10:]).strftime(\"%b%d\") + '/VaticOutput.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1febd-14b4-4598-9c23-df92175e8602",
   "metadata": {},
   "source": [
    "## Step 2: processing clnSim scenarios to aggregated-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9b786c3-fa5b-4060-83b6-953265450bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Feb14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Feb13\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Aug08\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jun04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/May27\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Nov13\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Sep14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Apr24\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/May10\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Apr01\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Dec27\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Apr09\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jul22\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jul24\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Mar14\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jan02\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jun30\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Feb26\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Dec01\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Oct17\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Nov02\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Oct04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Sep04\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Aug18\n",
      "/Users/Guille/Dropbox/ProcessedDataTexas/vatic_output/Texas-7k/ProcessedDataTexas/Jan20\n",
      "(1000, 24, 25) (1000, 24, 25) (1000, 24, 25) (1000, 24, 25) (1000, 24, 25) (1000, 4, 25)\n",
      "['2018-01-02' '2018-01-20' '2018-02-13' '2018-02-14' '2018-02-26'\n",
      " '2018-03-14' '2018-04-01' '2018-04-09' '2018-04-24' '2018-05-10'\n",
      " '2018-05-25' '2018-06-04' '2018-06-30' '2018-07-22' '2018-07-24'\n",
      " '2018-08-08' '2018-08-18' '2018-09-04' '2018-09-14' '2018-10-02'\n",
      " '2018-10-17' '2018-11-02' '2018-11-13' '2018-12-01' '2018-12-27']\n"
     ]
    }
   ],
   "source": [
    "# Load csv avoiding errors in the headers\n",
    "def __read_csv_file(file_name):\n",
    "    with open(file_name) as _file:\n",
    "        rows_ = []\n",
    "        for row in csv.reader(_file, delimiter = ','):\n",
    "            row = np.asarray(row)[:, np.newaxis]\n",
    "            rows_.append(row)\n",
    "    rows_.pop(0)\n",
    "    return np.concatenate(rows_, axis = 1).T\n",
    "\n",
    "L_, S_, W_, G_, N_, Y_ = [], [], [], [], [], []\n",
    "\n",
    "# Find All Simulations per Dates/Folders\n",
    "files_ = glob.glob(path_to_data + r'*')\n",
    "for file in files_:\n",
    "    print(file)\n",
    "            \n",
    "    L_.append( __read_csv_file(file + '/LoadScenariosAggregated.csv').astype(np.float_)[..., np.newaxis] )\n",
    "    S_.append( __read_csv_file(file + '/SolarScenariosAggregated.csv').astype(np.float_)[..., np.newaxis] )\n",
    "    W_.append( __read_csv_file(file + '/WindScenariosAggregated.csv').astype(np.float_)[..., np.newaxis] )\n",
    "    G_.append( S_[-1] + W_[-1] )\n",
    "    N_.append( L_[-1] - S_[-1] - W_[-1] )\n",
    "    Y_.append( __read_csv_file(file + '/VaticOutput.csv').astype(np.float_)[..., np.newaxis] )\n",
    "\n",
    "L_ = np.concatenate(L_, axis = -1)\n",
    "S_ = np.concatenate(S_, axis = -1)\n",
    "W_ = np.concatenate(W_, axis = -1)\n",
    "G_ = np.concatenate(G_, axis = -1)\n",
    "N_ = np.concatenate(N_, axis = -1)\n",
    "Y_ = np.concatenate(Y_, axis = -1)\n",
    "print(L_.shape, S_.shape, W_.shape, G_.shape, N_.shape, Y_.shape)\n",
    "\n",
    "dates_ = ['2018-02-14', '2018-02-13', '2018-08-08', '2018-06-04', '2018-05-25',\n",
    "          '2018-11-13', '2018-09-14', '2018-04-24', '2018-05-10', '2018-04-01',\n",
    "          '2018-12-27', '2018-04-09', '2018-07-22', '2018-07-24', '2018-03-14',\n",
    "          '2018-01-02', '2018-06-30', '2018-02-26', '2018-12-01', '2018-10-17',\n",
    "          '2018-11-02', '2018-10-02', '2018-09-04', '2018-08-18', '2018-01-20']\n",
    "\n",
    "idx_dates_ = np.argsort(dates_)\n",
    "print(np.array(dates_)[idx_dates_])\n",
    "\n",
    "with open(path_to_fdepth + 'ProcessedAggregatedData.pkl', 'wb') as handle:\n",
    "    pickle.dump([L_[..., idx_dates_], S_, W_[..., idx_dates_], G_[..., idx_dates_], N_[..., idx_dates_], Y_[..., idx_dates_]], handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c135ec-c6c3-45d5-9897-017184aabae4",
   "metadata": {},
   "source": [
    "## Step 3: processing clnSim scenarios to zonal-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "527408f1-5d8e-44ed-9d3e-f5d9ba17dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-10\n",
      "2018-09-04\n",
      "2018-02-26\n",
      "2018-12-27\n",
      "2018-09-14\n",
      "2018-11-13\n",
      "2018-01-02\n",
      "2018-08-18\n",
      "2018-04-24\n",
      "2018-06-30\n",
      "2018-03-14\n",
      "2018-04-09\n",
      "2018-08-08\n",
      "2018-11-02\n",
      "2018-01-20\n",
      "2018-04-01\n",
      "2018-06-04\n",
      "2018-12-01\n",
      "2018-10-04\n",
      "2018-02-13\n",
      "2018-07-22\n",
      "2018-05-27\n",
      "2018-10-17\n",
      "2018-07-24\n",
      "2018-02-14\n",
      "['2018-01-02' '2018-01-20' '2018-02-13' '2018-02-14' '2018-02-26'\n",
      " '2018-03-14' '2018-04-01' '2018-04-09' '2018-04-24' '2018-05-10'\n",
      " '2018-05-27' '2018-06-04' '2018-06-30' '2018-07-22' '2018-07-24'\n",
      " '2018-08-08' '2018-08-18' '2018-09-04' '2018-09-14' '2018-10-04'\n",
      " '2018-10-17' '2018-11-02' '2018-11-13' '2018-12-01' '2018-12-27']\n",
      "(24, 1000, 8, 25) (24, 1000, 8, 25) (24, 1000, 8, 25) (1000, 4, 25)\n"
     ]
    }
   ],
   "source": [
    "# Vatic reports\n",
    "L_ = []\n",
    "S_ = []\n",
    "W_ = []\n",
    "dates_ = []\n",
    "# Loop over files in directory\n",
    "for file_ in glob.glob(path_to_vatic + 'ProcessedScenTexas/' + '*'):\n",
    "    print(file_[-14:-4])\n",
    "    dates_.append(file_[-14:-4])\n",
    "    # Load data\n",
    "    with open(file_, 'rb') as _f:\n",
    "        scen_ = pickle.load(_f)\n",
    "    # Split data per asset\n",
    "    load_data_, load_zones_, _              = scen_[0]\n",
    "    solar_data_, solar_zones_, solar_names_ = scen_[1]\n",
    "    wind_data_, wind_zones_, wind_names_    = scen_[2]\n",
    "    load_zones_                             = np.array(load_zones_)\n",
    "    # Processing data\n",
    "    solar_ = []\n",
    "    wind_  = []\n",
    "    for zone in load_zones_:\n",
    "        idx_ = solar_zones_ == zone\n",
    "\n",
    "        if idx_.sum() == 0:\n",
    "            solar_.append(np.zeros((1, 1000, 24)))\n",
    "        else:\n",
    "            solar_.append(np.sum(solar_data_[idx_, ...], axis = 0)[np.newaxis, ...])\n",
    "\n",
    "        idx_ = wind_zones_ == zone\n",
    "        if idx_.sum() == 0:\n",
    "            wind_.append(np.zeros((1, 1000, 24)))\n",
    "        else:\n",
    "            wind_.append(np.sum(wind_data_[idx_, ...], axis = 0)[np.newaxis, ...])\n",
    "            \n",
    "    # Formated data\n",
    "    L_.append(load_data_)\n",
    "    S_.append(np.swapaxes(np.concatenate(solar_, axis = 0), 1, 2))\n",
    "    W_.append(np.swapaxes(np.concatenate(wind_, axis = 0), 1, 2))\n",
    "    \n",
    "idx_dates_ = np.argsort(dates_)\n",
    "print(np.array(dates_)[idx_dates_])\n",
    "\n",
    "L_ = np.swapaxes(np.swapaxes(np.swapaxes(np.stack(L_), 0, -1), 1, 2), 1, 0)[..., idx_dates_]\n",
    "S_ = np.swapaxes(np.swapaxes(np.swapaxes(np.stack(S_), 0, -1), 1, 2), 1, 0)[..., idx_dates_]\n",
    "W_ = np.swapaxes(np.swapaxes(np.swapaxes(np.stack(W_), 0, -1), 1, 2), 1, 0)[..., idx_dates_]\n",
    "print(L_.shape, S_.shape, W_.shape, Y_.shape)\n",
    "    \n",
    "\n",
    "# Save processed data\n",
    "with open(path_to_fdepth + 'ProcessedZonalTexas.pkl', 'wb') as _f:\n",
    "    pickle.dump([L_, S_, W_, S_ + W_, L_ - S_ - W_, Y_], _f, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dd185-6a59-4c1e-ab38-390d18a03263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
